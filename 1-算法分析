#大O数量级用来评判算法的复杂度指标O(n)
"""
常见的大O数量级函数
f(n)      名称
 1        #常数
 log(n)   #对数
 n        #线性
 n*log(n) #对数线性
 n^2      #平方
 n^3      #立方
 2^n      #指数
 
 
 "变位词"判断问题(可以很好展示同一个问题的不同数量级算法)
""" 
解法1:逐字检查

def anagramSolution1(s1,s2):
    #复制s2到列表
    alist = list(s2)
    pos1 = 0
    stillok = True
    #循环s1的每个字符
    while pos1 < len(s1) and stillok:
        pos2=0
        found= False
        #在s2逐个对比
        while pos2 < len(alist) and not found:
            if s1[pos1] ==alist[pos2]:
                  found = True
             else:
                  pos2 = pos2+1
          if found:
                #找到，打勾
                alist[pos2] = None
           else:
                #未找到，失败
                stillok = False
           pos1 = pos1  + 1
      return stillok
      
解法2：排序比较
def anagramSolution2(s1.s2):
    #转为列表
    alist =  list(s1)
    alist2 = list(s2)
    #分别排序
    alist1.sort()
    alist2.sort()
    pos = 0
    matches = True
    while pos < len(s1) and matches:
          #逐个对比
          if alist1[pos] == alist2[pos]:
              pos = pos+1
          else:
              matches = False
     return matches
#字符串无法排序，转为列表就可以
虽然数量级减少，但时间花在排序上


解法3：暴力法
#暴力法：穷尽所有可能组合
#将s1中出现的字符进行全排列，再查看s2是否出现在全排列列表中
#这里最大的困难是产生s1所有字符的全排列

已知n！增长速度甚至超过2^n
结论：暴力法不是个好方法

解法4：计数法
解题思路:对比两个词中每个字母出现的次数，如果26个字母出现的次数都相同的话，这两个字符串就一定是变位词
具体做法:为每个词设置一个26为计数器，先检查每个词，在计数器中设定好每个字母出现的次数

计数完成后，进入比较阶段，看两个字符串的计数器是否相同，如果相同则输出是变为词的结论

def anagramSolution(s1,s2):
    c1 = [0]*26
    c2 = [0]*26
    #分别计数
    for i in range(len(s1)):
        pos=ord(s1[i])-ord('a')
        c1[pos]=c2[pos] +1
    j=0
    stillok = True
    #计数比较
    while j<26 and stillok:
          if c1[j] == c2[j]:
              j = j+1
          else: 
              stillok = False
     return stillok      

#o(n)性能比较优


python数据类型的性能

#讨论python两种内置数据类型上各种操作的大O数量级
#列表list和字典dict

对比list和dict的操作
类型    list                dict
索引    自然数i             不可类型值key
        append、extend、   
添加    insert              b[k]=v
删除    pop、remove*        pop
更新    a[i]=v              b[k]=v
正查    a[i]、a[i:j]        b[k]、copy
反查    index(v)、count(v)  无
其他    reverse、sort       has_key、update
 
 4种生成前n个整数列表的方法
 首先是循环连接列表(+)方式生成
 def test1():
      l=[]
      for i in range(1000):
          l = l + [i]
 然后是用append 方法添加元素生成
 def test1():
      l=[]
      for i in range(1000):
          l.append(i)
  接着用列表推导式来做
  def test3():
      l=[i for i in range(1000)]
  最后是range函数调用转换成列表
  def test():
      l=list(range(1000))
      
       
 使用timeit模块对函数计时
 
 创建一个Timer对象，指定需要反复运行的语句和只需运行一次的“安装语句”
 然后调用这个对象的timeit方法，其中可以指定反复运行多少次
 
 from timeit import Timer
 t1 = Timer("test1()","from __main__ import test1")
 print("concat %f seconds\n" % t1.timeit(number=1000))
 
 t2 = Timer("test2()","from __main__ import test2")
 print("concat %f seconds\n" % t2.timeit(number=1000))


 t3 = Timer("test3()","from __main__ import test3")
 print("concat %f seconds\n" % t3.timeit(number=1000))

 t4 = Timer("test4()","from __main__ import test4")
 print("concat %f seconds\n" % t4.timeit(number=1000))
 
 
 >>>
concat 1.642524 seconds

concat 0.123054 seconds

concat 0.039721 seconds

concat 0.014553 seconds


列表连接（concat）最慢，List range最快，速度相差近200倍
append也要比concat快得多

list.pop的计时试验
pop从列表末尾移除元素，O(1)
pop（i）从列表中部移除元素 O(n)

原因在于Python所选择的是实现方法
从中部移除元素的话，要把移除元素后面的元素全部向前挪位复制一遍，这个看起来有点笨拙
但这种是实现方法能够保证列表按索引取值和赋值的操作很快，达到O(1)
这也算是一种对常用和不常用操作的折衷方案


import timeit
popzero = timeit.Timer("x.pop(0)","from __main__ import x")
popend = timeit.Timer("x.pop()","from __main__ import x")
>>>x=list(range(2000000))
>>>popzero.timeit(number=1000)
2.1306031 # 和老师运行结果不一样 0.7688910461739789
>>>x=list(range(2000000))
>>>popend.timeit(number=1000)
0.00016399999999983095  #0.0007347123802041722

相差10000倍，#老师相差1000倍

我们通过改变列表的大小来测试两个操作的增长趋势
import timeit
popzero = timeit.Timer("x.pop(0),"from __main__ import x")
popend = timeit.Timer("x.pop()","from __main__ import x")
print("pop(0) pop()")
for i in range(1000000,100000001,1000000):
    x = list(range(i))
    pt=popend.timeit(number=1000)
    x=list(range(i))
    pz=popzero.timeit(number=1000)
    print("%15.5f,%15.5f",%(pz,pt))
>>>
pop(0) pop()
        1.09136,        0.00007
        2.28644,        0.00008
        3.38415,        0.00008
        4.33298,        0.00007
        5.25571,        0.00008
        6.45311,        0.00008
        7.61143,        0.00008
        8.76898,        0.00008
        9.87427,        0.00008
       10.91641,        0.00020
       12.00500,        0.00009
       12.56542,        0.00021
       15.73194,        0.00008
       17.67356,        0.00024
       18.68122,        0.00007
#截取一部分
可以看出一个是线性增长，一个是常数

dict数据类型

字典与列表不同，根据关键码（key）找到数据项，而列表是根据位置（index）

最常用的取值get和赋值set，其性能为O(1),另一个重要操作contains(in)是判断字典中是否
存在某个关键码(key),这个性能也是O(1)

设计一个性能试验来验证list中检索一个值，以及dict中检索一个值的计时对比
生成包含连续值得list和包含连续关键码key得dict，用随机数来检验操作符in得耗时

list和dict的in操作对比

import timeit
import random

for i in range(10000,1000001,20000):
    t = timeit.Timer("random.randrange(%d) in x"%i,"from __main__ import random,x")
    x = list(range(i))
    
    x=list(range(i))
    lst_time = t.timeit(number=1000)
    x={j:None for j in range(i)}
    d_time = t.timeit(number=1000)
    print("%d,%10.3f,%10.3f"%(i,lst_time,d_time))
>>>
10000,     0.144,     0.001
30000,     0.234,     0.001
50000,     0.337,     0.001
70000,     0.491,     0.001
90000,     0.614,     0.002
110000,     0.822,     0.001
130000,     0.935,     0.001
150000,     1.320,     0.002
170000,     1.366,     0.002
190000,     2.188,     0.002
210000,     1.771,     0.002
230000,     1.907,     0.002
250000,     2.257,     0.002
270000,     2.306,     0.002
290000,     2.365,     0.002
310000,     2.430,     0.003
330000,     2.764,     0.002
350000,     2.962,     0.001
370000,     3.185,     0.002
390000,     3.401,     0.001
410000,     3.241,     0.002
430000,     3.519,     0.001
450000,     3.481,     0.001
470000,     4.114,     0.002
490000,     4.553,     0.001
510000,     3.667,     0.002

*可见字典的执行时间与规模无关，是常数
*而列表的执行时间则随着列表的规模加大而线性上升

python官方的算法复杂度网站：
http：//wiki.python.org/moin/TimeComplexity

















